---
title: "Logistic Regression Model"
author: "Jill Bolland"
date: "22/10/2021"
output: html_document
---
##  Data import 

 Use the full classified data set
 
```{r}
 
library(data.table)

filename = "C:/Users/j/Documents/Uni/ComSci 760/Weather Project/Data/recategorised_data.csv"

# note use stringsAsFactors = false the the Date variable is not converted to a factor

EntDataFull = read.csv(filename, stringsAsFactors = FALSE)

# convert the Date to a date format
EntDataFull$DATE = as.Date(EntDataFull$DATE)

# convert categorical data to factors.  Cat variables in columns 11 to 16
for (cat in 11:16) {EntDataFull[, cat] = as.factor(EntDataFull[, cat])}

# Also get into date order
EntDataFull = EntDataFull[order(EntDataFull$DATE), ]

```

```{r}
# Histograms 

par(mfrow=c(3, 3))

for (i in 2:9) {
    hist(EntDataFull[,i],  main= names(EntDataFull)[i], col = 'blue')
}

# put back to 1 by 1 charts
par(mfrow=c(1, 1))
```
#### Scatter plots of the variables

```{r}
library(s20x)
# scatter plot of Entero & rain variables
pairs20x(EntDataFull[2:6])

# scatter plot of Entero & Wind & solar
pairs20x(EntDataFull[c(2,7:9)])

```


```{r}
# get the last 10% of data and keep as the test data
# make sure the data is sorted in time and then calculate the number of observations and split the last 10 %

# set the test proportion to 10%  
testProp = 0.10
# need to round so we get whole number  0 dp
trainDataLength = round(nrow(EntDataFull)*(1-testProp),0)

#Drop the date and Entero data and BeachName & rainWA
# Add Entero Level as Class 

cleanData = EntDataFull[,c(3:5,7:9,11,16)]
cleanData$Class = EntDataFull$Entero_level

train = cleanData[1:trainDataLength,]
test =  cleanData[(trainDataLength+1):nrow(cleanData),]

```

####  GAM predicting with actual Data

```{r}
library(gam)

# set up the plot window 3 x 3 plots
par(mfrow=c(3,3))

#fit the gam - use Binomial family as we have binary class data
# from the scatterplots it looks like we need a smoothing spline of 2 for rainfall but only 1 for others

gamFit = gam(Class ~ s(Rain24, 2) + s(Rain48, 2) + s(Rain72, 2) +s(Wdirection) +s(Wspeed,1) + s(Solarhours,1) + BeachType + on_offshore, 
              data=train, family=binomial()) 


summary(gamFit)
plot(gamFit,  residuals = TRUE)

# back to one plot only
par(mfrow=c(1,1)) 
```


```{r}

# get prediction
yhat_gamFit  = as.numeric(predict(gamFit, newdata=test)>0.5)

# show the confusion table
table(test$Class, yhat_gamFit) 

# classification accuracy
(PE_yhat_gamFit = mean(test$Class == yhat_gamFit))

# show the confusion table
(confusionMatrix = table(test$Class, yhat_gamFit))

(modelAccuracy = sum(diag(confusionMatrix))/sum(confusionMatrix))
# True positive rate  
(modelSensitivity = confusionMatrix[2,2]/rowSums(confusionMatrix)[2])
# True negative rate  
(modelSepicificy = confusionMatrix[1,1]/rowSums(confusionMatrix)[1])

cat("model accuracy = " ,modelAccuracy*100, "% ")
cat("model Sensitivity  = " ,modelSensitivity*100, "% ")
cat("model Sepicificy = " ,modelSepicificy*100, "% ") 
```



####  Use Smote to oversample the data.  Categorical data are just copied rather than sampled


```{r}
library(mlr)
library(imbalance)

# osRate is the factor for increase in unbalanced data
osRate = as.integer(floor(table(train$Class)[1]/table(train$Class)[2]))

# first make a task
classifyTask = makeClassifTask(data = train, target = "Class")

# get the sampled data into a dataframe
trainOS = mlr::smote(classifyTask, osRate)[["env"]][["data"]]

# check the frequency table to check it is balanced
(table(trainOS$Class))

# Compare the new and old training data
plotComparison(train, rbind(train, trainOS), attrs = names(train)[1:3])
plotComparison(train, rbind(train, trainOS), attrs = names(train)[4:6])
summary(trainOS)

```
####  GAM predicting with oversampled Data  - trainOS_SMOTE oversampling

```{r}
library(gam)

# set up the plot window 3 x 3 plots
par(mfrow=c(3,3))

#fit the gam - use Binomial family as we have binary class data
# from the scatterplots it looks like we need a smoothing spline of 2 for rainfall but only 1 for others

gamFitOS = gam(Class ~ s(Rain24, 2) + s(Rain48, 2) + s(Rain72, 2) +s(Wdirection) +s(Wspeed) + s(Solarhours,1) + BeachType + on_offshore, 
              data=trainOS, family=binomial()) 


summary(gamFitOS)
plot(gamFitOS,  residuals = TRUE)

# back to one plot only
par(mfrow=c(1,1)) 
```


```{r}

# get prediction
yhat_gamFitOS  = as.numeric(predict(gamFitOS, newdata=test)>0.5)

# show the confusion table
table(test$Class, yhat_gamFitOS) 

# classification accuracy
(PE_yhat_gamFitOS = mean(test$Class == yhat_gamFitOS))

# show the confusion table
(confusionMatrix = table(test$Class, yhat_gamFitOS))

(modelAccuracy = sum(diag(confusionMatrix))/sum(confusionMatrix))
# True positive rate  
(modelSensitivity = confusionMatrix[2,2]/rowSums(confusionMatrix)[2])
# True negative rate  
(modelSepicificy = confusionMatrix[1,1]/rowSums(confusionMatrix)[1])

cat("model accuracy = " ,modelAccuracy*100, "% ")
cat("model Sensitivity  = " ,modelSensitivity*100, "% ")
cat("model Sepicificy = " ,modelSepicificy*100, "% ") 
```

# rolling prediction


```{r}
library(mlr)
library(imbalance)

# rolling prediction takes the final fitted model and does train and test splits in a rolling window with the train window expanding each time

# test size which stays the same each time is defaulted for our data with 5 steps of 40 values in each step.

steps = 5
testSize = 40
# Initialise first train length
startTrainLength = trainDataLength
rollPred = matrix(NA,testSize,steps)
metricsRoll = matrix(NA,5,3)  # 5 cols by 3 metrics

for (i in 1 : steps){
  trainData = cleanData[1:startTrainLength,]
  testData =  cleanData[(startTrainLength+1):(startTrainLength + testSize),]
  # get the smote samples
  # osRate is the factor for increase in unbalanced data
  osRate = as.integer(floor(table(train$Class)[1]/table(train$Class)[2]))
  # first make a task
  classifyTask = makeClassifTask(data = trainData, target = "Class")
  # get the sampled data into a dataframe
  trainOSRoll = mlr::smote(classifyTask, osRate)[["env"]][["data"]]
  # fit the model
  gamFitRoll = gam(Class ~ s(Rain24, 2) + s(Rain48, 2) +s(Wspeed, 1)  + BeachType + on_offshore, 
              data=trainOSRoll, family=binomial())
  # test on predictions
  yhat_gamFitRoll  = as.numeric(predict(gamFitRoll, newdata=testData)>0.5)
  rollPred[,i] = yhat_gamFitRoll
  confusionMatrixRoll = table(testData$Class, yhat_gamFitRoll)
  # add accuracy to metrics matrix
  metricsRoll[i,1] = sum(diag(confusionMatrixRoll))/sum(confusionMatrixRoll)  
  # add sensitivity to metrics matrix
  metricsRoll[i,2] = confusionMatrixRoll[2,2]/rowSums(confusionMatrixRoll)[2] 
  # add specificity to metrics matrix
  metricsRoll[i,3] = confusionMatrixRoll[1,1]/rowSums(confusionMatrixRoll)[1]
  # increase the startTrain length
  startTrainLength = startTrainLength + testSize
}

metricsRoll

(avgMetrics = colMeans(metricsRoll)*100)
```
# sliding prediction


```{r}
library(mlr)
library(imbalance)

# window  prediction takes the final fitted model and does train and test splits in a rolling window with the train and test size staying the same each time with a moving windo

# test size which stays the same each time is defaulted for our data with 5 steps of 40 values in each step.

steps = 5
testSize = 40
# Initialise first train length
startTrainLength = trainDataLength
trainStart = 1
windowPred = matrix(NA,testSize,steps)
metricsWindow = matrix(NA,5,3)  # 5 cols by 3 metrics

for (i in 1 : steps){
  trainData = cleanData[trainStart:startTrainLength,]
  testData =  cleanData[(startTrainLength+1):(startTrainLength + testSize),]
  # get the smote samples
  # osRate is the factor for increase in unbalanced data
  osRate = as.integer(floor(table(train$Class)[1]/table(train$Class)[2]))
  # first make a task
  classifyTask = makeClassifTask(data = trainData, target = "Class")
  # get the sampled data into a dataframe
  trainOSRoll = mlr::smote(classifyTask, osRate)[["env"]][["data"]]
  # fit the model
  gamFitRoll = gam(Class ~ s(Rain24, 2) + s(Rain48, 2) +s(Wspeed, 1)  + BeachType + on_offshore, 
              data=trainOSRoll, family=binomial())
  # test on predictions
  yhat_gamFitRoll  = as.numeric(predict(gamFitRoll, newdata=testData)>0.5)
  windowPred[,i] = yhat_gamFitRoll
  confusionMatrixRoll = table(testData$Class, yhat_gamFitRoll)
  # add accuracy to metrics matrix
  metricsWindow[i,1] = sum(diag(confusionMatrixRoll))/sum(confusionMatrixRoll)  
  # add sensitivity to metrics matrix
  metricsWindow[i,2] = confusionMatrixRoll[2,2]/rowSums(confusionMatrixRoll)[2] 
  # add specificity to metrics matrix
  metricsWindow[i,3] = confusionMatrixRoll[1,1]/rowSums(confusionMatrixRoll)[1]
  # increase the startTrain length
  startTrainLength = startTrainLength + testSize
  trainStart = trainStart + testSize
}

metricsWindow

(avgMetrics = colMeans(metricsWindow)*100)
```



