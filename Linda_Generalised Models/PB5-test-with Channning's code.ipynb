{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d61ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from matplotlib import style\n",
    "#style.use('fivethirtyeight')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#!pip install imblearn\n",
    "from imblearn.over_sampling import ADASYN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44f965e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entero</th>\n",
       "      <th>Rain24</th>\n",
       "      <th>Rain48</th>\n",
       "      <th>Rain72</th>\n",
       "      <th>RainWA</th>\n",
       "      <th>Wdirection</th>\n",
       "      <th>Wspeed</th>\n",
       "      <th>Solarhours</th>\n",
       "      <th>BeachType</th>\n",
       "      <th>BeachDirection</th>\n",
       "      <th>Entero_level</th>\n",
       "      <th>Wspeed_level</th>\n",
       "      <th>Wdirection_level</th>\n",
       "      <th>on_offshore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>182.596926</td>\n",
       "      <td>2.052960</td>\n",
       "      <td>4.378617</td>\n",
       "      <td>6.878463</td>\n",
       "      <td>13.310040</td>\n",
       "      <td>187.879028</td>\n",
       "      <td>2.702033</td>\n",
       "      <td>6.703718</td>\n",
       "      <td>0.491324</td>\n",
       "      <td>4.221616</td>\n",
       "      <td>0.073872</td>\n",
       "      <td>1.010412</td>\n",
       "      <td>8.029251</td>\n",
       "      <td>0.869113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1271.550681</td>\n",
       "      <td>5.678971</td>\n",
       "      <td>9.307389</td>\n",
       "      <td>12.594966</td>\n",
       "      <td>25.209095</td>\n",
       "      <td>90.915915</td>\n",
       "      <td>1.670540</td>\n",
       "      <td>3.849683</td>\n",
       "      <td>0.500049</td>\n",
       "      <td>4.995729</td>\n",
       "      <td>0.261627</td>\n",
       "      <td>0.106303</td>\n",
       "      <td>4.073803</td>\n",
       "      <td>0.861271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>7.730000</td>\n",
       "      <td>15.160000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24196.000000</td>\n",
       "      <td>57.900000</td>\n",
       "      <td>115.250000</td>\n",
       "      <td>127.320000</td>\n",
       "      <td>251.620000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Entero       Rain24       Rain48       Rain72       RainWA  \\\n",
       "count   2017.000000  2017.000000  2017.000000  2017.000000  2017.000000   \n",
       "mean     182.596926     2.052960     4.378617     6.878463    13.310040   \n",
       "std     1271.550681     5.678971     9.307389    12.594966    25.209095   \n",
       "min       10.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       10.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       10.000000     0.000000     0.490000     1.460000     2.420000   \n",
       "75%       20.000000     0.980000     4.290000     7.730000    15.160000   \n",
       "max    24196.000000    57.900000   115.250000   127.320000   251.620000   \n",
       "\n",
       "        Wdirection       Wspeed   Solarhours    BeachType  BeachDirection  \\\n",
       "count  2017.000000  2017.000000  2017.000000  2017.000000     2017.000000   \n",
       "mean    187.879028     2.702033     6.703718     0.491324        4.221616   \n",
       "std      90.915915     1.670540     3.849683     0.500049        4.995729   \n",
       "min       0.000000     0.000000     0.000000     0.000000        1.000000   \n",
       "25%     113.000000     1.500000     3.500000     0.000000        1.000000   \n",
       "50%     211.000000     2.400000     7.200000     0.000000        2.000000   \n",
       "75%     253.000000     3.400000    10.000000     1.000000       10.000000   \n",
       "max     360.000000    14.200000    14.100000     1.000000       15.000000   \n",
       "\n",
       "       Entero_level  Wspeed_level  Wdirection_level  on_offshore  \n",
       "count   2017.000000   2017.000000       2017.000000  2017.000000  \n",
       "mean       0.073872      1.010412          8.029251     0.869113  \n",
       "std        0.261627      0.106303          4.073803     0.861271  \n",
       "min        0.000000      0.000000          0.000000     0.000000  \n",
       "25%        0.000000      1.000000          5.000000     0.000000  \n",
       "50%        0.000000      1.000000          9.000000     1.000000  \n",
       "75%        0.000000      1.000000         11.000000     2.000000  \n",
       "max        1.000000      2.000000         15.000000     2.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import recategorised data\n",
    "wholedata = pd.read_csv(\"recategorised_data.csv\")\n",
    "wholedata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4b2b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Entero</th>\n",
       "      <th>Rain24</th>\n",
       "      <th>Rain48</th>\n",
       "      <th>Rain72</th>\n",
       "      <th>RainWA</th>\n",
       "      <th>Wdirection</th>\n",
       "      <th>Wspeed</th>\n",
       "      <th>Solarhours</th>\n",
       "      <th>BeachName</th>\n",
       "      <th>BeachType</th>\n",
       "      <th>BeachDirection</th>\n",
       "      <th>Entero_level</th>\n",
       "      <th>Wspeed_level</th>\n",
       "      <th>Wdirection_level</th>\n",
       "      <th>on_offshore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995-12-16</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.17</td>\n",
       "      <td>13.67</td>\n",
       "      <td>37.00</td>\n",
       "      <td>59.84</td>\n",
       "      <td>200</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Clarks</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-12-27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>230</td>\n",
       "      <td>5.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Clarks</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-12-28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>320</td>\n",
       "      <td>3.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>Clarks</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996-01-07</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>130</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Clarks</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996-01-08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Clarks</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  Entero  Rain24  Rain48  Rain72  RainWA  Wdirection  Wspeed  \\\n",
       "0  1995-12-16    10.0    9.17   13.67   37.00   59.84         200     1.5   \n",
       "1  1995-12-27    10.0    0.00    0.00    0.33    0.33         230     5.7   \n",
       "2  1995-12-28    10.0    2.50    2.50    2.50    7.50         320     3.6   \n",
       "3  1996-01-07    10.0    0.00    0.00    0.00    0.00         130     4.1   \n",
       "4  1996-01-08    10.0    0.00    0.00    0.00    0.00         100     3.6   \n",
       "\n",
       "   Solarhours BeachName  BeachType  BeachDirection  Entero_level  \\\n",
       "0         1.8    Clarks          1              15             0   \n",
       "1         8.5    Clarks          1              15             0   \n",
       "2        11.7    Clarks          1              15             0   \n",
       "3         7.9    Clarks          1              15             0   \n",
       "4         4.4    Clarks          1              15             0   \n",
       "\n",
       "   Wspeed_level  Wdirection_level  on_offshore  \n",
       "0             1                 9            0  \n",
       "1             1                10            2  \n",
       "2             1                14            1  \n",
       "3             1                 6            0  \n",
       "4             1                 4            2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wholedata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b1e495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 105 entries, 215 to 2016\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   DATE              105 non-null    datetime64[ns]\n",
      " 1   Rain24            105 non-null    float64       \n",
      " 2   Rain48            105 non-null    float64       \n",
      " 3   Rain72            105 non-null    float64       \n",
      " 4   Solarhours        105 non-null    float64       \n",
      " 5   BeachType         105 non-null    int64         \n",
      " 6   Wspeed_level      105 non-null    int64         \n",
      " 7   Wdirection_level  105 non-null    int64         \n",
      " 8   on_offshore       105 non-null    int64         \n",
      " 9   Entero_level      105 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(5)\n",
      "memory usage: 9.0 KB\n"
     ]
    }
   ],
   "source": [
    "wholedata['DATE']=wholedata['DATE'].astype('datetime64')\n",
    "# put aside test_set for final test\n",
    "test_set = wholedata[wholedata['DATE'].dt.year>=2017]\n",
    "test_set = test_set.drop([\"Entero\", \"RainWA\", \"BeachName\", \"Wspeed\", \"Wdirection\", \"BeachDirection\"], axis=1)\n",
    "test_set['DATE']=test_set['DATE'].astype('datetime64')\n",
    "test_set = test_set.reindex(columns=(list([c for c in test_set.columns if c != \"Entero_level\"]) + [\"Entero_level\"]))\n",
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b71e698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1543 entries, 803 to 1997\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   DATE              1543 non-null   datetime64[ns]\n",
      " 1   Rain24            1543 non-null   float64       \n",
      " 2   Rain48            1543 non-null   float64       \n",
      " 3   Rain72            1543 non-null   float64       \n",
      " 4   Solarhours        1543 non-null   float64       \n",
      " 5   BeachType         1543 non-null   int64         \n",
      " 6   Wspeed_level      1543 non-null   int64         \n",
      " 7   Wdirection_level  1543 non-null   int64         \n",
      " 8   on_offshore       1543 non-null   int64         \n",
      " 9   Entero_level      1543 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(5)\n",
      "memory usage: 132.6 KB\n"
     ]
    }
   ],
   "source": [
    "# train/validation set excluding test_set\n",
    "data_frame = wholedata[wholedata['DATE'].dt.year<2017]\n",
    "data_frame = data_frame[data_frame['DATE'].dt.year>=2000]\n",
    "recategorised_data = data_frame.sort_values(by=['DATE'])\n",
    "recategorised_data = recategorised_data.drop([\"Entero\", \"RainWA\", \"BeachName\", \"Wspeed\", \"Wdirection\", \"BeachDirection\"], axis=1)\n",
    "recategorised_data['DATE']=recategorised_data['DATE'].astype('datetime64')\n",
    "recategorised_data = recategorised_data.reindex(columns=(list([c for c in recategorised_data.columns if c != \"Entero_level\"]) + [\"Entero_level\"]))\n",
    "recategorised_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffd7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state\n",
    "RANDOM_STATE = 1234\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Extract features and label\n",
    "def extract(dataframe):\n",
    "    X = np.array(dataframe.iloc[:, 1:-1])\n",
    "    y = np.array(dataframe.iloc[:, -1])\n",
    "    return X, y\n",
    "\n",
    "# Timeseries split\n",
    "ts = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Cross-validation split\n",
    "kf = KFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f2a0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv(hyperparameters, fit_model):\n",
    "    # Length of the test set\n",
    "    l_test = 0\n",
    "\n",
    "    # Pre-allocate space for results\n",
    "    cv = np.zeros((ts.n_splits, kf.n_splits, len(hyperparameters)))\n",
    "\n",
    "    # Multi-split the data into train sets and test sets in a timely manner\n",
    "    ts_idx = -1\n",
    "    for train_index, test_index in ts.split(recategorised_data):    \n",
    "        ts_idx += 1\n",
    "        train, test = recategorised_data.iloc[train_index, :], recategorised_data.iloc[test_index, :]\n",
    "        l_test = len(test_index)\n",
    "\n",
    "        # Cross-validate train sets to get the best hyperparameter(s)\n",
    "        kf_idx = -1\n",
    "        for train_index, validation_index in kf.split(train):\n",
    "            kf_idx += 1\n",
    "            X_train, y_train = extract(train.iloc[train_index, :])\n",
    "            X_valdn, y_valdn = extract(train.iloc[validation_index, :])\n",
    "\n",
    "            # Fit the scaler to X_train, and then use it to transform both the train set and the test set\n",
    "            transfromer = preprocessing.Normalizer().fit(X_train[:, 0:3])\n",
    "            X_train[:, 0:3] = transfromer.transform(X_train[:, 0:3])\n",
    "            X_valdn[:, 0:3] = transfromer.transform(X_valdn[:, 0:3])\n",
    "\n",
    "            # Oversample the train set with ADASYN\n",
    "            adasyn = ADASYN(sampling_strategy=\"minority\", n_neighbors=1)\n",
    "            X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Test hyperparameters\n",
    "            idx = -1\n",
    "            for i in hyperparameters:\n",
    "                idx += 1\n",
    "                knn = fit_model(i)\n",
    "                knn.fit(X_train, y_train)\n",
    "\n",
    "                # Better safe than sorry, so the true negative rate is what we care the most - should be true positive rate\n",
    "                tn, fp, fn, tp = confusion_matrix(y_valdn, knn.predict(X_valdn)).ravel()\n",
    "                cv[ts_idx, kf_idx, idx] = tp/(tp+fn)\n",
    "    return l_test, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82163d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walking_eval(l_test, fitted_model):\n",
    "    r = []\n",
    "    # Evaluation by walking backwards, i.e. remove 6 obesersations from the test set at one step until it runs out\n",
    "    for i in range(0, l_test, 6):\n",
    "        train = recategorised_data.iloc[0:-(l_test+i), :]\n",
    "        test = recategorised_data.iloc[-(l_test+i):, :]\n",
    "\n",
    "        X_train, y_train = extract(train)\n",
    "        X_test, y_test = extract(test)\n",
    "\n",
    "        transfromer = preprocessing.Normalizer().fit(X_train[:, 0:3])\n",
    "        X_train[:, 0:3] = transfromer.transform(X_train[:, 0:3])\n",
    "        X_test[:, 0:3] = transfromer.transform(X_test[:, 0:3])\n",
    "\n",
    "        adasyn = ADASYN(sampling_strategy=\"minority\", n_neighbors=1)\n",
    "        X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Plug in the best hyperparameter(s) from cv\n",
    "        knn = fitted_model\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, knn.predict(X_test)).ravel()\n",
    "        r.append(tp/(tp+fn))\n",
    "    return np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf60aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best KNN is with 9 neighbour(s)\n",
      "The best KNN is with an average sensitivity of 0.396903274729783\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "# Train\n",
    "neighbors = range(1, 10, 1)\n",
    "def knn(i):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    return knn\n",
    "l_test, cv = rolling_cv(neighbors, knn)\n",
    "\n",
    "means = np.mean(cv, axis=(0,1))\n",
    "best = neighbors[np.argmax(means)]\n",
    "print(\"The best KNN is with %s neighbour(s)\" %(best))\n",
    "\n",
    "# Evaluate\n",
    "fitted_model = knn(best)\n",
    "r = walking_eval(l_test, fitted_model)\n",
    "\n",
    "print(\"The best KNN is with an average sensitivity of %s\" %(np.mean(r)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e7c4dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score\n",
      "0.6285714285714286\n",
      "Confusion matrix\n",
      "[[59 29]\n",
      " [10  7]]\n",
      "Targets\n",
      "215     0\n",
      "216     0\n",
      "217     0\n",
      "218     0\n",
      "219     0\n",
      "       ..\n",
      "2012    0\n",
      "2013    0\n",
      "2014    0\n",
      "2015    0\n",
      "2016    0\n",
      "Name: Entero_level, Length: 105, dtype: int64\n",
      "Predictions\n",
      "[0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1\n",
      " 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Final KNN model test on separate test-set\n",
    "test_set_data = test_set.iloc[:,1:-1]\n",
    "#test_set_data = sc.transform(test_set_data)\n",
    "test_set_labels = test_set.iloc[:,-1]\n",
    "\n",
    "print(\"Accuracy score\")\n",
    "print(fitted_model.score(test_set_data,test_set_labels))\n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(test_set_labels,fitted_model.predict(test_set_data)))\n",
    "print(\"Targets\")\n",
    "print(test_set_labels)\n",
    "print(\"Predictions\")\n",
    "print(fitted_model.predict(test_set_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1739ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best BDT is with a learning rate of 0.1\n",
      "The best BDT is with an average sensitivity of 0.4294089214118263\n"
     ]
    }
   ],
   "source": [
    "# BDT\n",
    "# Train\n",
    "learning_rates = np.linspace(0.1, 1, 9)\n",
    "def ada(i):\n",
    "    ada = AdaBoostClassifier(learning_rate=i)\n",
    "    return ada\n",
    "l_test, cv = rolling_cv(learning_rates, ada)\n",
    "\n",
    "means = np.mean(cv, axis=(0,1))\n",
    "best = learning_rates[np.argmax(means)]\n",
    "print(\"The best BDT is with a learning rate of %s\" %(best))\n",
    "\n",
    "# Evaluate\n",
    "fitted_model = ada(best)\n",
    "r = walking_eval(l_test, fitted_model)\n",
    "\n",
    "print(\"The best BDT is with an average sensitivity of %s\" %(np.mean(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad1d74dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score\n",
      "0.6761904761904762\n",
      "Confusion matrix\n",
      "[[70 18]\n",
      " [16  1]]\n",
      "Targets\n",
      "215     0\n",
      "216     0\n",
      "217     0\n",
      "218     0\n",
      "219     0\n",
      "       ..\n",
      "2012    0\n",
      "2013    0\n",
      "2014    0\n",
      "2015    0\n",
      "2016    0\n",
      "Name: Entero_level, Length: 105, dtype: int64\n",
      "Predictions\n",
      "[0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Final BDT model test on separate test-set\n",
    "test_set_data = test_set.iloc[:,1:-1]\n",
    "#test_set_data = sc.transform(test_set_data)\n",
    "test_set_labels = test_set.iloc[:,-1]\n",
    "\n",
    "print(\"Accuracy score\")\n",
    "print(fitted_model.score(test_set_data,test_set_labels))\n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(test_set_labels,fitted_model.predict(test_set_data)))\n",
    "print(\"Targets\")\n",
    "print(test_set_labels)\n",
    "print(\"Predictions\")\n",
    "print(fitted_model.predict(test_set_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf4179d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "walking_eval() missing 1 required positional argument: 'fitted_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d3e78a2dfa86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# For the completeness of the experiment design, evaluate ANN on a setting off the top of my head\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mann\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sgd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adaptive\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwalking_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mann\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The average sensitivity for the ANNs is %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: walking_eval() missing 1 required positional argument: 'fitted_model'"
     ]
    }
   ],
   "source": [
    "# ANN\n",
    "# Skip the training part as the data set is not large enough to tune the hyperparameters properly for ANN\n",
    "\n",
    "# For the completeness of the experiment design, evaluate ANN on a setting off the top of my head\n",
    "ann = MLPClassifier(solver=\"sgd\", learning_rate=\"adaptive\", hidden_layer_sizes=(4, 2), max_iter=1000) \n",
    "r = walking_eval(ann)\n",
    "print(\"The average sensitivity for the ANNs is %s\" %(np.mean(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfe806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
