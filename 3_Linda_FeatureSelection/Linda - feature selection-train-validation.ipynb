{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd07df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impot modules\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#from autorank import autorank, plot_stats, create_report, latex_table\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7066f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recategorised_data = pd.read_csv(\"recategorised_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d38066",
   "metadata": {},
   "outputs": [],
   "source": [
    "recategorised_data = recategorised_data.drop([\"Entero\", \"RainWA\", \"BeachName\", \"Wspeed_level\", \"Wdirection_level\", \"BeachDirection\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e26a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recategorsied data for modelling\n",
    "# recategorised_data = recategorised_data.drop([\"Entero\", \"RainWA\", \"BeachName\", \"Wspeed\", \"Wdirection\", \"BeachDirection\"], axis=1)\n",
    "\n",
    "# Converted to datatime64 for ordering\n",
    "recategorised_data[\"DATE\"] = recategorised_data[\"DATE\"].astype(\"datetime64\")\n",
    "\n",
    "# Converted to catogory for oversampling\n",
    "#recategorised_data[\"Wspeed_level\"] = recategorised_data[\"Wspeed_level\"].astype(\"category\")\n",
    "recategorised_data[\"BeachType\"] = recategorised_data[\"BeachType\"].astype(\"category\")\n",
    "recategorised_data[\"on_offshore\"] = recategorised_data[\"on_offshore\"].astype(\"category\")\n",
    "#recategorised_data[\"Wdirection_level\"] = recategorised_data[\"Wdirection_level\"].astype(\"category\")\n",
    "\n",
    "# Scale down the categorical features to (0, 1)\n",
    "#recategorised_data[\"Wspeed_level\"] = recategorised_data[\"Wspeed_level\"].apply(lambda x: x/recategorised_data['Wspeed_level'].nunique())\n",
    "recategorised_data[\"BeachType\"] = recategorised_data[\"BeachType\"].apply(lambda x: x/recategorised_data['BeachType'].nunique())\n",
    "recategorised_data[\"on_offshore\"] = recategorised_data[\"on_offshore\"].apply(lambda x: x/recategorised_data['on_offshore'].nunique())\n",
    "#recategorised_data[\"Wdirection_level\"] = recategorised_data[\"Wdirection_level\"].apply(lambda x: x/recategorised_data['Wdirection_level'].nunique())\n",
    "\n",
    "# Rearrange the features, so numerics comes first for nomalisation\n",
    "recategorised_data = recategorised_data.reindex(columns=(list([c for c in recategorised_data.columns if c != \"Entero_level\"]) + [\"Entero_level\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69044cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2017 entries, 0 to 2016\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   DATE          2017 non-null   datetime64[ns]\n",
      " 1   Rain24        2017 non-null   float64       \n",
      " 2   Rain48        2017 non-null   float64       \n",
      " 3   Rain72        2017 non-null   float64       \n",
      " 4   Wdirection    2017 non-null   int64         \n",
      " 5   Wspeed        2017 non-null   float64       \n",
      " 6   Solarhours    2017 non-null   float64       \n",
      " 7   BeachType     2017 non-null   category      \n",
      " 8   on_offshore   2017 non-null   category      \n",
      " 9   Entero_level  2017 non-null   int64         \n",
      "dtypes: category(2), datetime64[ns](1), float64(5), int64(2)\n",
      "memory usage: 130.4 KB\n"
     ]
    }
   ],
   "source": [
    "recategorised_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece42617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/validation set info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1816 entries, 0 to 1157\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   Rain24        1816 non-null   float64 \n",
      " 1   Rain48        1816 non-null   float64 \n",
      " 2   Rain72        1816 non-null   float64 \n",
      " 3   Wdirection    1816 non-null   int64   \n",
      " 4   Wspeed        1816 non-null   float64 \n",
      " 5   Solarhours    1816 non-null   float64 \n",
      " 6   BeachType     1816 non-null   category\n",
      " 7   on_offshore   1816 non-null   category\n",
      " 8   Entero_level  1816 non-null   int64   \n",
      "dtypes: category(2), float64(5), int64(2)\n",
      "memory usage: 117.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Set random state\n",
    "RANDOM_STATE = 1234\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Set test size\n",
    "test_size = 201\n",
    "\n",
    "# Set the number of splits\n",
    "n_split = 5\n",
    "\n",
    "# Set the number of observations at each step\n",
    "n_obsn = 40\n",
    "\n",
    "# Order data by date\n",
    "recategorised_data = recategorised_data.sort_values(by=['DATE'])\n",
    "recategorised_data = recategorised_data.drop(\"DATE\", axis=1)\n",
    "\n",
    "# Extract features and label (X-predictor variables, y-response variable-last column)\n",
    "def extract(dataframe):\n",
    "    X = dataframe.iloc[:, 0:-1]\n",
    "    y = dataframe.iloc[:, -1]\n",
    "    return X, y\n",
    "\n",
    "# Timeseries split for rolling \"cross validation\"\n",
    "ts = TimeSeriesSplit(n_splits=n_split)\n",
    "\n",
    "# Create train/validation set which excluds the test set for evaluation\n",
    "cv_dataset = recategorised_data.iloc[:-test_size, :]\n",
    "print(\"Train/validation set info:\")\n",
    "cv_dataset.info()\n",
    "\n",
    "# The DataFrame to store model performances for autorank\n",
    "df = pd.DataFrame(columns=[\"KNN\", \"BDT\", \"ANN\"])\n",
    "dfAcc = pd.DataFrame(columns=[\"KNN\", \"BDT\", \"ANN\"])\n",
    "dfSp = pd.DataFrame(columns=[\"KNN\", \"BDT\", \"ANN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93dda5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature correlation analysis:\n",
      "                Rain24    Rain48    Rain72  Wdirection    Wspeed  Solarhours  \\\n",
      "Rain24        1.000000  0.708130  0.538913    0.017648  0.070324   -0.241831   \n",
      "Rain48        0.708130  1.000000  0.828864    0.055917  0.085008   -0.173784   \n",
      "Rain72        0.538913  0.828864  1.000000    0.055594  0.075347   -0.169193   \n",
      "Wdirection    0.017648  0.055917  0.055594    1.000000 -0.062360    0.139224   \n",
      "Wspeed        0.070324  0.085008  0.075347   -0.062360  1.000000   -0.071385   \n",
      "Solarhours   -0.241831 -0.173784 -0.169193    0.139224 -0.071385    1.000000   \n",
      "Entero_level  0.170314  0.182479  0.166256   -0.052237  0.089490   -0.051465   \n",
      "\n",
      "              Entero_level  \n",
      "Rain24            0.170314  \n",
      "Rain48            0.182479  \n",
      "Rain72            0.166256  \n",
      "Wdirection       -0.052237  \n",
      "Wspeed            0.089490  \n",
      "Solarhours       -0.051465  \n",
      "Entero_level      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Feature correlation analysis \n",
    "print(\"Feature correlation analysis:\")\n",
    "print(cv_dataset.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847c8442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 1\n",
      "Selected Features: ['Solarhours']\n",
      "Feature Ranking: [8 7 4 2 3 1 5 6]\n",
      "Num Features: 1\n",
      "Selected Features: ['Rain72']\n",
      "Feature Ranking: [3 6 1 2 4 5 7 8]\n",
      "Num Features: 1\n",
      "Selected Features: ['Rain48']\n",
      "Feature Ranking: [5 1 4 2 6 3 8 7]\n",
      "Num Features: 1\n",
      "Selected Features: ['Solarhours']\n",
      "Feature Ranking: [5 4 6 3 2 1 8 7]\n",
      "Num Features: 1\n",
      "Selected Features: ['Rain72']\n",
      "Feature Ranking: [6 5 1 4 3 2 8 7]\n",
      "Num Features: 2\n",
      "Selected Features: ['Rain72' 'Solarhours']\n",
      "Feature Ranking: [4 6 1 3 2 1 7 5]\n",
      "Num Features: 2\n",
      "Selected Features: ['Rain72' 'Wdirection']\n",
      "Feature Ranking: [4 3 1 1 5 2 6 7]\n",
      "Num Features: 2\n",
      "Selected Features: ['Rain24' 'Rain48']\n",
      "Feature Ranking: [1 1 5 2 3 4 7 6]\n",
      "Num Features: 2\n",
      "Selected Features: ['Rain48' 'Solarhours']\n",
      "Feature Ranking: [3 1 4 5 2 1 7 6]\n",
      "Num Features: 2\n",
      "Selected Features: ['Rain72' 'Wspeed']\n",
      "Feature Ranking: [5 4 1 2 1 3 7 6]\n",
      "Num Features: 3\n",
      "Selected Features: ['Wdirection' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [5 3 2 1 1 1 6 4]\n",
      "Num Features: 3\n",
      "Selected Features: ['Rain24' 'Rain72' 'Wdirection']\n",
      "Feature Ranking: [1 3 1 1 4 2 5 6]\n",
      "Num Features: 3\n",
      "Selected Features: ['Rain48' 'Wdirection' 'Wspeed']\n",
      "Feature Ranking: [2 1 4 1 1 3 6 5]\n",
      "Num Features: 3\n",
      "Selected Features: ['Wdirection' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [3 4 2 1 1 1 6 5]\n",
      "Num Features: 3\n",
      "Selected Features: ['Rain72' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [4 3 1 2 1 1 6 5]\n",
      "Num Features: 4\n",
      "Selected Features: ['Wdirection' 'Wspeed' 'Solarhours' 'on_offshore']\n",
      "Feature Ranking: [4 5 2 1 1 1 3 1]\n",
      "Num Features: 4\n",
      "Selected Features: ['Rain24' 'Rain72' 'Wdirection' 'Solarhours']\n",
      "Feature Ranking: [1 2 1 1 5 1 3 4]\n",
      "Num Features: 4\n",
      "Selected Features: ['Rain24' 'Rain48' 'Wdirection' 'Wspeed']\n",
      "Feature Ranking: [1 1 2 1 1 3 5 4]\n",
      "Num Features: 4\n",
      "Selected Features: ['Rain48' 'Rain72' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [2 1 1 3 1 1 5 4]\n",
      "Num Features: 4\n",
      "Selected Features: ['Rain72' 'Wdirection' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [3 2 1 1 1 1 5 4]\n",
      "Num Features: 5\n",
      "Selected Features: ['Wdirection' 'Wspeed' 'Solarhours' 'BeachType' 'on_offshore']\n",
      "Feature Ranking: [4 3 2 1 1 1 1 1]\n",
      "Num Features: 5\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Solarhours']\n",
      "Feature Ranking: [1 1 1 1 2 1 3 4]\n",
      "Num Features: 5\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed']\n",
      "Feature Ranking: [1 1 1 1 1 2 4 3]\n",
      "Num Features: 5\n",
      "Selected Features: ['Rain24' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [1 2 1 1 1 1 4 3]\n",
      "Num Features: 5\n",
      "Selected Features: ['Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [2 1 1 1 1 1 4 3]\n",
      "Num Features: 6\n",
      "Selected Features: ['Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours' 'on_offshore']\n",
      "Feature Ranking: [3 1 1 1 1 1 2 1]\n",
      "Num Features: 6\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Solarhours' 'BeachType']\n",
      "Feature Ranking: [1 1 1 1 2 1 1 3]\n",
      "Num Features: 6\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [1 1 1 1 1 1 3 2]\n",
      "Num Features: 6\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [1 1 1 1 1 1 3 2]\n",
      "Num Features: 6\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours']\n",
      "Feature Ranking: [1 1 1 1 1 1 3 2]\n",
      "Num Features: 7\n",
      "Selected Features: ['Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours' 'BeachType'\n",
      " 'on_offshore']\n",
      "Feature Ranking: [2 1 1 1 1 1 1 1]\n",
      "Num Features: 7\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours' 'BeachType']\n",
      "Feature Ranking: [1 1 1 1 1 1 1 2]\n",
      "Num Features: 7\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours'\n",
      " 'on_offshore']\n",
      "Feature Ranking: [1 1 1 1 1 1 2 1]\n",
      "Num Features: 7\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours'\n",
      " 'on_offshore']\n",
      "Feature Ranking: [1 1 1 1 1 1 2 1]\n",
      "Num Features: 7\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours'\n",
      " 'on_offshore']\n",
      "Feature Ranking: [1 1 1 1 1 1 2 1]\n",
      "Num Features: 8\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours' 'BeachType'\n",
      " 'on_offshore']\n",
      "Feature Ranking: [1 1 1 1 1 1 1 1]\n",
      "Num Features: 8\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours' 'BeachType'\n",
      " 'on_offshore']\n",
      "Feature Ranking: [1 1 1 1 1 1 1 1]\n",
      "Num Features: 8\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours' 'BeachType'\n",
      " 'on_offshore']\n",
      "Feature Ranking: [1 1 1 1 1 1 1 1]\n",
      "Num Features: 8\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours' 'BeachType'\n",
      " 'on_offshore']\n",
      "Feature Ranking: [1 1 1 1 1 1 1 1]\n",
      "Num Features: 8\n",
      "Selected Features: ['Rain24' 'Rain48' 'Rain72' 'Wdirection' 'Wspeed' 'Solarhours' 'BeachType'\n",
      " 'on_offshore']\n",
      "Feature Ranking: [1 1 1 1 1 1 1 1]\n",
      "Accuracy: [[0.         0.72516556 0.90066225 0.92715232 0.92384106 0.92384106\n",
      "  0.91721854 0.91059603 0.90728477]\n",
      " [0.         0.63245033 0.66225166 0.7615894  0.75496689 0.7384106\n",
      "  0.85099338 0.84437086 0.8410596 ]\n",
      " [0.         0.83443709 0.80794702 0.74834437 0.77483444 0.78145695\n",
      "  0.75165563 0.72516556 0.75496689]\n",
      " [0.         0.5794702  0.68211921 0.6589404  0.6589404  0.67549669\n",
      "  0.69205298 0.70198675 0.68211921]\n",
      " [0.         0.67880795 0.70529801 0.70198675 0.71854305 0.76490066\n",
      "  0.73509934 0.73509934 0.74172185]]\n",
      "Sensitivity: [[0.         0.22222222 0.16666667 0.05555556 0.         0.05555556\n",
      "  0.         0.11111111 0.        ]\n",
      " [0.         0.20833333 0.25       0.20833333 0.20833333 0.25\n",
      "  0.20833333 0.25       0.20833333]\n",
      " [0.         0.17857143 0.17857143 0.21428571 0.25       0.25\n",
      "  0.21428571 0.32142857 0.42857143]\n",
      " [0.         0.36       0.48       0.6        0.48       0.48\n",
      "  0.52       0.4        0.4       ]\n",
      " [0.         0.5        0.38888889 0.38888889 0.5        0.44444444\n",
      "  0.33333333 0.33333333 0.44444444]]\n",
      "Specificity: [[0.         0.75704225 0.9471831  0.98239437 0.98239437 0.97887324\n",
      "  0.97535211 0.96126761 0.96478873]\n",
      " [0.         0.66906475 0.69784173 0.80935252 0.80215827 0.78057554\n",
      "  0.90647482 0.89568345 0.89568345]\n",
      " [0.         0.90145985 0.87226277 0.80291971 0.82846715 0.83576642\n",
      "  0.80656934 0.76642336 0.78832117]\n",
      " [0.         0.59927798 0.70036101 0.66425993 0.67509025 0.69314079\n",
      "  0.70758123 0.72924188 0.70758123]\n",
      " [0.         0.69014085 0.72535211 0.72183099 0.73239437 0.78521127\n",
      "  0.76056338 0.76056338 0.76056338]]\n"
     ]
    }
   ],
   "source": [
    "# Feature selection with time split validation:\n",
    "\n",
    "# Pre-allocate space for results\n",
    "acc = np.zeros((ts.n_splits, 9))\n",
    "sen = np.zeros((ts.n_splits, 9))\n",
    "spe = np.zeros((ts.n_splits, 9))\n",
    "tsfs =  [[[]] * 9  for j in range(ts.n_splits)]\n",
    "c=cv_dataset.iloc[:,0:8].columns\n",
    "\n",
    "for feature_number in range(1, 9):\n",
    "\n",
    "    # Multi-split the data into train sets and validation sets in a timely manner\n",
    "    ts_idx = -1\n",
    "    for train_index, validation_index in ts.split(cv_dataset):    \n",
    "        ts_idx += 1\n",
    "        train, validation = cv_dataset.iloc[train_index, :], cv_dataset.iloc[validation_index, :]\n",
    "        \n",
    "        X_train, y_train = extract(train)\n",
    "        X_valdn, y_valdn = extract(validation)\n",
    "        \n",
    "        # Fit the scaler to X_train, and then use it to transform both the train set and the test set\n",
    "        transfromer = preprocessing.Normalizer().fit(X_train.iloc[:, 0:6])\n",
    "        X_train.iloc[:, 0:6] = transfromer.transform(X_train.iloc[:, 0:6])\n",
    "        X_valdn.iloc[:, 0:6] = transfromer.transform(X_valdn.iloc[:, 0:6])\n",
    "        #print(\"X_train.head():\",X_train.head())\n",
    "        #print(\"X_valdn.head():\",X_valdn.head())\n",
    "\n",
    "        # Oversample the train set with SMOTENC\n",
    "        smotenc = SMOTENC(categorical_features=[X_train.dtypes==\"category\"], sampling_strategy=\"minority\", k_neighbors=1)\n",
    "        X_train, y_train = smotenc.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Run feature selection\n",
    "        # Feature extraction-Recursive Feature Elimination (or RFE)\n",
    "        #rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=feature_number)\n",
    "        rfe = RFE(estimator=AdaBoostClassifier(), n_features_to_select=feature_number)\n",
    "        #rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=feature_number)\n",
    "        \n",
    "        fit = rfe.fit(X_train, y_train)\n",
    "        print(\"Num Features: %s\" % (fit.n_features_))\n",
    "        print(\"Selected Features: %s\" % (c[fit.support_].values))\n",
    "        print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
    "        tsfs[ts_idx][feature_number] = list(c[fit.support_].values)\n",
    "        #print(tsfs_f)\n",
    "            \n",
    "        cm1 = confusion_matrix(y_valdn, fit.predict(X_valdn))\n",
    "        total1=sum(sum(cm1))\n",
    "        #####from confusion matrix calculate accuracy\n",
    "        acc[ts_idx, feature_number] = (cm1[0,0]+cm1[1,1])/total1\n",
    "        sen[ts_idx, feature_number] = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "        spe[ts_idx, feature_number] = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "        # print(confusion_matrix(y_valdn, fit.predict(X_valdn)))\n",
    "print(\"Accuracy:\",acc)\n",
    "print(\"Sensitivity:\",sen)\n",
    "print(\"Specificity:\",spe)\n",
    "#tsfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501fb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Best accuracy:\", np.max(acc), \"Features selected:\", tsfs[math.floor(np.argmax(acc)/9)][np.argmax(acc)%9])\n",
    "#print(\"Best sensitivity:\", np.max(sen), \"Features selected:\", tsfs[math.floor(np.argmax(sen)/9)][np.argmax(sen)%9])\n",
    "#print(\"Best specificity:\", np.max(spe), \"Features selected:\", tsfs[math.floor(np.argmax(spe)/9)][np.argmax(spe)%9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0808547d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours', 'on_offshore'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Solarhours', 'BeachType'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours'] \n"
     ]
    }
   ],
   "source": [
    "# Best feature combination by average accuracy\n",
    "acc_mean = np.mean(acc, axis=0)\n",
    "for i in range(5): \n",
    "    print(tsfs[i][np.argmax(acc_mean)], end = \" \") \n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a3a953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours', 'BeachType', 'on_offshore'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours', 'BeachType', 'on_offshore'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours', 'BeachType', 'on_offshore'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours', 'BeachType', 'on_offshore'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours', 'BeachType', 'on_offshore'] \n"
     ]
    }
   ],
   "source": [
    "# Best feature combination by average sensitivity\n",
    "sen_mean = np.mean(sen, axis=0)\n",
    "for i in range(5): \n",
    "    print(tsfs[i][np.argmax(sen_mean)], end = \" \") \n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c27fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours', 'on_offshore'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Solarhours', 'BeachType'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours'] \n",
      "['Rain24', 'Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours'] \n"
     ]
    }
   ],
   "source": [
    "# Best feature combination by average specificity\n",
    "spe_mean = np.mean(spe, axis=0)\n",
    "for i in range(5): \n",
    "    print(tsfs[i][np.argmax(spe_mean)], end = \" \") \n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98c42e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wdirection', 'Wspeed', 'Solarhours']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Wdirection', 'Wspeed', 'Solarhours', 'on_offshore', 'Entero_level']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose feature combination for the final model\n",
    "col = tsfs[math.floor(np.argmax(sen)/9)][np.argmax(sen)%9]\n",
    "print(col)\n",
    "if 'on_offshore' not in col:\n",
    "    col = col + ['on_offshore']\n",
    "col = col + ['Entero_level']\n",
    "#col = ['Rain48', 'Rain72', 'Wdirection', 'Wspeed', 'Solarhours', 'BeachType', 'on_offshore']\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "761cc8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1816 entries, 0 to 1157\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   Rain24        1816 non-null   float64 \n",
      " 1   Rain48        1816 non-null   float64 \n",
      " 2   Rain72        1816 non-null   float64 \n",
      " 3   Wdirection    1816 non-null   int64   \n",
      " 4   Wspeed        1816 non-null   float64 \n",
      " 5   Solarhours    1816 non-null   float64 \n",
      " 6   BeachType     1816 non-null   category\n",
      " 7   on_offshore   1816 non-null   category\n",
      " 8   Entero_level  1816 non-null   int64   \n",
      "dtypes: category(2), float64(5), int64(2)\n",
      "memory usage: 117.3 KB\n"
     ]
    }
   ],
   "source": [
    "#cv_dataset = cv_dataset[col]\n",
    "cv_dataset.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
